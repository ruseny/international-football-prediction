{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the models with Euro 24 results\n",
    "\n",
    "In this notebook, we test the two models with Euro 24 data, which was unseen during model training. The idea is to see if training specifically for big tournaments makes a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained with qualification phase performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import processed data and slice the Euro 24 games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euro24_qual = pd.read_pickle(\"../data/processed/qualification_performance.pkl\")\n",
    "df_euro24_qual = df_euro24_qual[df_euro24_qual[\"period\"] == \"Euro24\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_feature_names = []\n",
    "\n",
    "for ab in [\"A\", \"B\"]:\n",
    "    for metric in [\"win_ratio\", \"draw_ratio\", \"avg_goals_scored\", \"avg_goals_conceded\"]:\n",
    "        qual_feature_names.append(f\"{ab}_{metric}\")\n",
    "\n",
    "qual_feature_names.append(\"host_advantage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature and target sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_qual = df_euro24_qual[qual_feature_names].copy()\n",
    "y_test_qual = df_euro24_qual[[\"result\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       A_win       0.52      0.55      0.53        22\n",
      "       B_win       0.42      0.83      0.56        12\n",
      "        Draw       0.75      0.18      0.29        17\n",
      "\n",
      "    accuracy                           0.49        51\n",
      "   macro avg       0.56      0.52      0.46        51\n",
      "weighted avg       0.57      0.49      0.46        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qual_model = joblib.load(\"../models/qual_perf_model.pkl\")\n",
    "y_pred_qual = qual_model.predict(X_test_qual)\n",
    "print(classification_report(y_test_qual, y_pred_qual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance seems better than what had been observed during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained on rolling window performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import processed data and slice Euro 24 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euro24_rolling = pd.read_pickle(\"../data/processed/rolling_performance.pkl\")\n",
    "df_euro24_rolling = df_euro24_rolling[(df_euro24_rolling[\"tournament\"] == \"UEFA Euro\") & (df_euro24_rolling[\"date\"] >= datetime(2024, 6, 14))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_feature_names = []\n",
    "\n",
    "for ha in [\"home\", \"away\"]:\n",
    "    for metric in [\"win_ratio\", \"draw_ratio\", \"avg_goals_scored\", \"avg_goals_conceded\"]:\n",
    "        rolling_feature_names.append(f\"{ha}_{metric}_roll730D\")\n",
    "\n",
    "rolling_feature_names.append(\"host_advantage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature and target sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rolling = df_euro24_rolling[rolling_feature_names].copy()\n",
    "y_test_rolling = df_euro24_rolling[[\"result\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    away_win       0.33      0.85      0.48        13\n",
      "        draw       0.25      0.18      0.21        17\n",
      "    home_win       0.50      0.14      0.22        21\n",
      "\n",
      "    accuracy                           0.33        51\n",
      "   macro avg       0.36      0.39      0.30        51\n",
      "weighted avg       0.37      0.33      0.28        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rolling_model = joblib.load(\"../models/rolling_model.pkl\")\n",
    "y_pred_rolling = rolling_model.predict(X_test_rolling)\n",
    "print(classification_report(y_test_rolling, y_pred_rolling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is quite bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Although rolling window model (trained to predict an match result) seemed to display better performance overall, qualification phase model (trained to predict only big tournament results) performed better when tested on the unseen data from Euro 24."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_football",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
